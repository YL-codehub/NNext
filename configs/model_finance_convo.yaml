all:
data:
  source: assets
  entities: ["AAPL", "MSFT", "AMZN", "GOOGL", "TSLA"] # entities are called 'tickers' in finance
  end_date: # expecting a %Y-%m-%d string, if None then taken as today
  duration: ['weeks',1000] #in datetime args format
  rolling_count: 13 #including n+1 in that case

  ## add something for feature engineering.
model:
  type: Sequential
  training:
    loss: MASELoss
    n_epochs: 1000
    batch_size: 750  # the MASE is not additive man...
    max_increases: 1000
    learning_rate: #0.1 #'scheduled_restart'
    optimiser: Adam
  architecture:
#   Best hyperparameters:  {'conv1_out_channels': 21, 'conv1_kernel_size': 3, 'conv2_out_channels': 98, 'conv2_kernel_size': 2, 'linear_layer_size': 62}
    - Conv1d:
        args: [5, 21, 3]  # input_channels, output_channels, kernel_size. 
        # Outcome has size = batchsize=32,nb_output_channels,floor(L_in-kernel_size+1)=11
    - ReLU:
        inplace: false
    - MaxPool1d:
        args: [2]  # pool_size
        # outcome has size = batchsize, channels = 64, L//2 = 6
    - Conv1d:
        args: [21, 98, 2]  # input_channels, output_channels, kernel_size
        ## L_out= 5
    - ReLU:
        inplace: false
    - MaxPool1d:
        args: [2]  # pool_size
        ## channels = 64, L//2 = 2
    - Flatten: {} #32,98*2
    - Linear:
        args: [196, 62]  # flattened_size depends on input shape after pooling
    - ReLU:
        inplace: false
    - Linear:
        args: [62, 30]  # flattened_size depends on input shape after pooling
    - ReLU:
        inplace: false
    - Linear:
        args: [30, 5]  # flattened_size depends on input shape after pooling
